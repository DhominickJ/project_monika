{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'using': 0.027725887222397813, 'bag': 0.027725887222397813, 'of': 0.08317766166719343, 'example': 0.027725887222397813, 'driven': 0.0, 'this': 0.027725887222397813, 'implementation': 0.027725887222397813, 'actual': 0.027725887222397813, 'test': 0.027725887222397813, 'a': 0.027725887222397813, 'bus': 0.0, 'to': 0.027725887222397813, 'is': 0.0, 'tf-idf': 0.027725887222397813, 'function': 0.027725887222397813, 'the': 0.0, 'The': 0.0, 'an': 0.027725887222397813, 'and': 0.027725887222397813, 'text': 0.055451774444795626, 'Hello,': 0.027725887222397813, 'words': 0.027725887222397813, 'sample': 0.027725887222397813, 'road': 0.0, 'on': 0.0}\n",
      "using : 0.027725887222397813\n",
      "bag : 0.027725887222397813\n",
      "of : 0.08317766166719343\n",
      "example : 0.027725887222397813\n",
      "driven : 0.0\n",
      "this : 0.027725887222397813\n",
      "implementation : 0.027725887222397813\n",
      "actual : 0.027725887222397813\n",
      "test : 0.027725887222397813\n",
      "a : 0.027725887222397813\n",
      "bus : 0.0\n",
      "to : 0.027725887222397813\n",
      "is : 0.0\n",
      "tf-idf : 0.027725887222397813\n",
      "function : 0.027725887222397813\n",
      "the : 0.0\n",
      "The : 0.0\n",
      "an : 0.027725887222397813\n",
      "and : 0.027725887222397813\n",
      "text : 0.055451774444795626\n",
      "Hello, : 0.027725887222397813\n",
      "words : 0.027725887222397813\n",
      "sample : 0.027725887222397813\n",
      "road : 0.0\n",
      "on : 0.0\n"
     ]
    }
   ],
   "source": [
    "def compute_tf(word_dict, bag_of_words):\n",
    "    tf_dict = {}\n",
    "    word_count = len(bag_of_words)\n",
    "    for word, count in word_dict.items():\n",
    "        tf_dict[word] = count / float(word_count)\n",
    "    return tf_dict\n",
    "\n",
    "def compute_idf(doc_list):\n",
    "    import math\n",
    "    idf_dict = {}\n",
    "    n = len(doc_list)\n",
    "    \n",
    "    idf_dict = dict.fromkeys(doc_list[0].keys(), 0)\n",
    "    for doc in doc_list:\n",
    "        for word, val in doc.items():\n",
    "            if val > 0:\n",
    "                idf_dict[word] += 1\n",
    "    \n",
    "    for word, val in idf_dict.items():\n",
    "        idf_dict[word] = math.log(n / float(val))\n",
    "        \n",
    "    return idf_dict\n",
    "\n",
    "def compute_tf_idf(tf_bag_of_words, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tf_bag_of_words.items():\n",
    "        tfidf[word] = val * idfs[word]\n",
    "    return tfidf\n",
    "\n",
    "doc_a = \"Hello, this is an example of a text using the text sample to test the bag of words function and the actual implementation of tf-idf\"\n",
    "doc_b = \"The bus is driven on the road\"\n",
    "\n",
    "bag_of_words_a = doc_a.split(\" \")\n",
    "bag_of_words_b = doc_b.split(\" \")\n",
    "\n",
    "word_set = set(bag_of_words_a).union(set(bag_of_words_b))\n",
    "\n",
    "word_dict_a = dict.fromkeys(word_set, 0) \n",
    "word_dict_b = dict.fromkeys(word_set, 0)\n",
    "\n",
    "for word in bag_of_words_a:\n",
    "    word_dict_a[word]+=1\n",
    "    \n",
    "for word in bag_of_words_b:\n",
    "    word_dict_b[word]+=1\n",
    "\n",
    "tf_bag_of_words_a = compute_tf(word_dict_a, bag_of_words_a)\n",
    "tf_bag_of_words_b = compute_tf(word_dict_b, bag_of_words_b)\n",
    "\n",
    "idfs = compute_idf([word_dict_a, word_dict_b])\n",
    "\n",
    "tfidf_bag_of_words_a = compute_tf_idf(tf_bag_of_words_a, idfs)\n",
    "tfidf_bag_of_words_b = compute_tf_idf(tf_bag_of_words_b, idfs)\n",
    "\n",
    "print(tfidf_bag_of_words_a)\n",
    "for key in tf_bag_of_words_a:\n",
    "    print(key + \" : \" + str(tfidf_bag_of_words_a[key]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the value of k\n",
    "# k = 5\n",
    "\n",
    "# # Define the knn classifier function\n",
    "# def knn_classifier(A, y, test_document):\n",
    "#   # Initialize an empty list to store the distances\n",
    "#   d = []\n",
    "#   # Get the number of documents and words\n",
    "#   numberOfDocuments, numberOfUniqueWords = A.shape\n",
    "#   # Loop through each document\n",
    "#   for i in range(numberOfDocuments):\n",
    "#     # Initialize the distance to zero\n",
    "#     distance = 0\n",
    "#     # Loop through each word\n",
    "#     for r in range(numberOfUniqueWords):\n",
    "#       # Add the squared difference of the tf-idf values\n",
    "#       distance += (A[r,i] - test_document[r])**2\n",
    "#     # Take the square root of the distance\n",
    "#     distance = distance**0.5\n",
    "#     # Append the distance and the label to the list\n",
    "#     d.append((distance, y[i]))\n",
    "#   # Sort the list by the distance in ascending order\n",
    "#   d.sort()\n",
    "#   # Get the k closest documents\n",
    "#   k_closest = d[:k]\n",
    "#   # Get the labels of the k closest documents\n",
    "#   k_labels = [label for distance, label in k_closest]\n",
    "#   # Count the frequency of each label\n",
    "#   label_counts = {}\n",
    "#   for label in k_labels:\n",
    "#     label_counts[label] = label_counts.get(label, 0) + 1\n",
    "#   # Get the label with the highest frequency\n",
    "#   max_count = 0\n",
    "#   max_label = None\n",
    "#   for label, count in label_counts.items():\n",
    "#     if count > max_count:\n",
    "#       max_count = count\n",
    "#       max_label = label\n",
    "#   # Return the label of the test document\n",
    "#   return max_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32md:\\Important_Tasks\\CCS226 - Introduction to Artificial Intelligence\\Project_Monika\\Finalized_Research\\TF-IDF\\tf-idf.ipynb Cell 3\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Important_Tasks/CCS226%20-%20Introduction%20to%20Artificial%20Intelligence/Project_Monika/Finalized_Research/TF-IDF/tf-idf.ipynb#W3sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m   \u001b[39m# Return the label of the last document\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Important_Tasks/CCS226%20-%20Introduction%20to%20Artificial%20Intelligence/Project_Monika/Finalized_Research/TF-IDF/tf-idf.ipynb#W3sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m max_label\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Important_Tasks/CCS226%20-%20Introduction%20to%20Artificial%20Intelligence/Project_Monika/Finalized_Research/TF-IDF/tf-idf.ipynb#W3sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m tf_sentence \u001b[39m=\u001b[39m knn_classifier(compute_tf_idf, tfidf_bag_of_words_a, idfs, labels, k)\n",
      "\u001b[1;32md:\\Important_Tasks\\CCS226 - Introduction to Artificial Intelligence\\Project_Monika\\Finalized_Research\\TF-IDF\\tf-idf.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Important_Tasks/CCS226%20-%20Introduction%20to%20Artificial%20Intelligence/Project_Monika/Finalized_Research/TF-IDF/tf-idf.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Loop through each document except the last one\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Important_Tasks/CCS226%20-%20Introduction%20to%20Artificial%20Intelligence/Project_Monika/Finalized_Research/TF-IDF/tf-idf.ipynb#W3sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(numberOfDocuments \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Important_Tasks/CCS226%20-%20Introduction%20to%20Artificial%20Intelligence/Project_Monika/Finalized_Research/TF-IDF/tf-idf.ipynb#W3sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m   \u001b[39m# Compute the tf-idf values for the current and last document\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Important_Tasks/CCS226%20-%20Introduction%20to%20Artificial%20Intelligence/Project_Monika/Finalized_Research/TF-IDF/tf-idf.ipynb#W3sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m   tfidf_current \u001b[39m=\u001b[39m compute_tf_idf(tf_bag_of_words[i], idfs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Important_Tasks/CCS226%20-%20Introduction%20to%20Artificial%20Intelligence/Project_Monika/Finalized_Research/TF-IDF/tf-idf.ipynb#W3sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m   tfidf_last \u001b[39m=\u001b[39m compute_tf_idf(tf_bag_of_words[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], idfs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Important_Tasks/CCS226%20-%20Introduction%20to%20Artificial%20Intelligence/Project_Monika/Finalized_Research/TF-IDF/tf-idf.ipynb#W3sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m   \u001b[39m# Initialize the distance to zero\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "labels = ['Cris', 'Sports', 'To']\n",
    "\n",
    "k = 3\n",
    "# Define the knn classifier function\n",
    "def knn_classifier(compute_tf_idf, tf_bag_of_words, idfs, labels, k):\n",
    "  # Initialize an empty list to store the distances\n",
    "  d = []\n",
    "  # Get the number of documents and words\n",
    "  numberOfDocuments = len(tf_bag_of_words)\n",
    "  # Loop through each document except the last one\n",
    "  for i in range(numberOfDocuments - 1):\n",
    "    # Compute the tf-idf values for the current and last document\n",
    "    tfidf_current = compute_tf_idf(tf_bag_of_words[i], idfs)\n",
    "    tfidf_last = compute_tf_idf(tf_bag_of_words[-1], idfs)\n",
    "    # Initialize the distance to zero\n",
    "    distance = 0\n",
    "    # Loop through each word\n",
    "    for word in tfidf_current.keys():\n",
    "      # Add the squared difference of the tf-idf values\n",
    "      distance += (tfidf_current[word] - tfidf_last[word])**2\n",
    "    # Take the square root of the distance\n",
    "    distance = distance**0.5\n",
    "    # Append the distance and the label to the list\n",
    "    d.append((distance, labels[i]))\n",
    "  # Sort the list by the distance in ascending order\n",
    "  d.sort()\n",
    "  # Get the k closest documents\n",
    "  k_closest = d[:k]\n",
    "  # Get the labels of the k closest documents\n",
    "  k_labels = [label for distance, label in k_closest]\n",
    "  # Count the frequency of each label\n",
    "  label_counts = {}\n",
    "  for label in k_labels:\n",
    "    label_counts[label] = label_counts.get(label, 0) + 1\n",
    "  # Get the label with the highest frequency\n",
    "  max_count = 0\n",
    "  max_label = None\n",
    "  for label, count in label_counts.items():\n",
    "    if count > max_count:\n",
    "      max_count = count\n",
    "      max_label = label\n",
    "  # Return the label of the last document\n",
    "  return max_label\n",
    "\n",
    "tf_sentence = knn_classifier(compute_tf_idf, tfidf_bag_of_words_a, idfs, labels, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
